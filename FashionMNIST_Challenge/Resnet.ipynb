{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# FashionMNIST Challenge 之 殘差卷積神經網絡"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 一、算法原理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 二、算法實現"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "from keras.models import model_from_json, load_model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "import numpy as np\n",
    "from keras.layers import Conv2D, BatchNormalization, MaxPooling2D, Input\n",
    "from keras.layers import AveragePooling2D, Flatten, GlobalMaxPooling2D\n",
    "from keras import layers\n",
    "from keras.models import Model\n",
    "\n",
    "def conv_block(input_tensor, bn_axis, filters, phase, name, strides=(1, 1)):\n",
    "    \"\"\"\n",
    "    Conv2D 塊，雙路雙卷積計算\n",
    "    :param input_tensor:(tensor) 輸入張量\n",
    "    :param filters:(tuple) 卷積核打包\n",
    "    :param strides:(int) 卷積步長\n",
    "    :param BN_axis:(int) 規範化卷積軸\n",
    "    :return: model\n",
    "    \"\"\"\n",
    "    filters1, filters2, filters3 = filters  # 解包卷積核數量\n",
    "    Conv_base_name = 'Conv_' + name + '_' + str(phase) + '_phase_'\n",
    "    BN_base_name = 'BN_' + name + '_' + str(phase) + '_phase_'\n",
    "    x = Conv2D(\n",
    "        filters=filters1, kernel_size=(1, 1), strides=strides, name=Conv_base_name + '2a'\n",
    "    )(input_tensor)\n",
    "    x = BatchNormalization(axis=bn_axis, name=BN_base_name + '2a')(x)\n",
    "    x = Activation(activation='relu')(x)\n",
    "\n",
    "    x = Conv2D(\n",
    "        filters=filters2, kernel_size=(1, 1), strides=strides, name=Conv_base_name + '2b'\n",
    "    )(x)\n",
    "    x = BatchNormalization(axis=bn_axis, name=BN_base_name + '2b')(x)\n",
    "    x = Activation(activation='relu')(x)\n",
    "\n",
    "    x = Conv2D(\n",
    "        filters=filters3, kernel_size=(1, 1), strides=strides, name=Conv_base_name + '2c'\n",
    "    )(x)\n",
    "    x = BatchNormalization(axis=bn_axis, name=BN_base_name + '2c')(x)\n",
    "    x = Activation(activation='relu')(x)\n",
    "\n",
    "    y = Conv2D(filters3, (1, 1), strides=strides, name=Conv_base_name + '1a')(input_tensor)\n",
    "    y = BatchNormalization(axis=bn_axis, name=BN_base_name + '1b')(y)\n",
    "\n",
    "    x = layers.add([x, y])\n",
    "    a = Activation('relu')(x)\n",
    "\n",
    "    return a\n",
    "\n",
    "\n",
    "def identity_block(input_tensor, bn_axis, filters, phase, name, strides=(1, 1)):\n",
    "    \"\"\"\n",
    "    Conv2D 塊，雙路單卷積計算\n",
    "    :param input_tensor:(tensor) 輸入張量\n",
    "    :param filters:(tuple) 卷積核打包\n",
    "    :param strides:(int) 卷積步長\n",
    "    :param BN_axis:(int) 規範化卷積軸\n",
    "    :return: model\n",
    "    \"\"\"\n",
    "    filters1, filters2, filters3 = filters  # 解包卷積核數量\n",
    "    Conv_base_name = 'Conv_' + name + '_' + str(phase) + '_phase_'\n",
    "    BN_base_name = 'BN_' + name + '_' + str(phase) + '_phase_'\n",
    "    x = Conv2D(\n",
    "        filters=filters1, kernel_size=(1, 1), strides=strides, name=Conv_base_name + '2a'\n",
    "    )(input_tensor)\n",
    "    x = BatchNormalization(axis=bn_axis, name=BN_base_name + '2a')(x)\n",
    "    x = Activation(activation='relu')(x)\n",
    "\n",
    "    x = Conv2D(\n",
    "        filters=filters2, kernel_size=(1, 1), strides=strides, name=Conv_base_name + '2b'\n",
    "    )(x)\n",
    "    x = BatchNormalization(axis=bn_axis, name=BN_base_name + '2b')(x)\n",
    "    x = Activation(activation='relu')(x)\n",
    "\n",
    "    x = Conv2D(\n",
    "        filters=filters3, kernel_size=(1, 1), strides=strides, name=Conv_base_name + '2c'\n",
    "    )(x)\n",
    "    x = BatchNormalization(axis=bn_axis, name=BN_base_name + '2c')(x)\n",
    "    x = Activation(activation='relu')(x)\n",
    "\n",
    "    x = layers.add([x, input_tensor])\n",
    "    a = Activation('relu')(x)\n",
    "\n",
    "    return a\n",
    "\n",
    "\n",
    "def my_resnet():\n",
    "    inputs = Input(shape=(1, 28, 28))\n",
    "\n",
    "    x = Conv2D(\n",
    "        filters=4, kernel_size=(3, 3), padding='same', name='Conv1', data_format='channels_first')(inputs)\n",
    "    x = BatchNormalization(axis=1, name='BN_Conv1')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    MaxPooling2D(pool_size=(2, 2), strides=(2, 2), data_format='channels_first')(x)\n",
    "\n",
    "    x = conv_block(input_tensor=x, bn_axis=1, filters=(4, 4, 64), phase=2, name='a')\n",
    "    x = identity_block(input_tensor=x, bn_axis=1, filters=(4, 4, 64), phase=2, name='b')\n",
    "    x = identity_block(input_tensor=x, bn_axis=1, filters=(4, 4, 64), phase=2, name='c')\n",
    "\n",
    "    x = AveragePooling2D((2, 2), name='avg_pool')(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(10, activation='softmax', name='softmax10')(x)\n",
    "    # x = GlobalMaxPooling2D()(x)\n",
    "\n",
    "    model = Model(inputs, x, name='My_Resnet')\n",
    "    return model\n",
    "\n",
    "\n",
    "def create_model():\n",
    "    \"\"\"返回一個已創建好的 resnet model\"\"\"\n",
    "    # model = keras.applications.resnet50.ResNet50(include_top=True, weights=None,\n",
    "    #                                              input_tensor=None, input_shape=(224, 224, 3),\n",
    "    #                                              pooling='max',\n",
    "    #                                              classes=10)\n",
    "    model = my_resnet()\n",
    "    model.compile(optimizer='rmsprop',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_tfrecord(filename, tensor=[1, 784], num=5000):\n",
    "    \"\"\"\n",
    "    讀取tfrecord文件數據\n",
    "    :param filename: 文件名\n",
    "    :param tensor: 緯度\n",
    "    :param num: 讀取數據數量\n",
    "    :return: images 圖片數據列表    labels(numpy) 標籤列表    maxlabels(int) 標籤所在項\n",
    "    \"\"\"\n",
    "    filename_queue = tf.train.string_input_producer([filename])\n",
    "    reader = tf.TFRecordReader()\n",
    "    _, serialized_example = reader.read(filename_queue)\n",
    "    features = tf.parse_single_example(serialized_example,\n",
    "                                       features={\n",
    "                                           'label': tf.FixedLenFeature([], tf.int64),\n",
    "                                           'img_val': tf.FixedLenFeature(tensor, tf.float32),\n",
    "                                       })\n",
    "    image = tf.cast(features['img_val'], tf.float64)\n",
    "    label = tf.cast(features['label'], tf.int32)\n",
    "    images = []\n",
    "    labels = []\n",
    "    maxlabels = []\n",
    "    with tf.Session() as sess:\n",
    "        init_op = tf.global_variables_initializer()\n",
    "        sess.run(init_op)\n",
    "        coord = tf.train.Coordinator()\n",
    "        threads = tf.train.start_queue_runners(coord=coord)\n",
    "        for i in range(num):\n",
    "            example, l = sess.run([image, label])\n",
    "            arr = np.array(example[0])\n",
    "            arr = arr.reshape((28, 28))\n",
    "            images.append([arr])\n",
    "            tem = np.zeros((1, 10))\n",
    "            tem[0][l] = 1.0\n",
    "            labels.append(tem[0])\n",
    "            maxlabels.append([l])\n",
    "            del tem\n",
    "        coord.request_stop()\n",
    "        coord.join(threads=threads)\n",
    "    images = np.array(images)\n",
    "    labels = np.array(labels)\n",
    "    return images, labels, maxlabels\n",
    "\n",
    "\n",
    "def trun(arr):\n",
    "    out_arr = []\n",
    "    for img in arr:\n",
    "        img = Image.fromarray(img.reshape([28, 28])).resize([224, 224])\n",
    "        img = np.asarray(img)\n",
    "        im = []\n",
    "        for a in img:\n",
    "            row = []\n",
    "            for b in a:\n",
    "                row.append([b, b + 0.0, b + 0.0])\n",
    "            im.append(row)\n",
    "            del row\n",
    "        out_arr.append(im)\n",
    "        del im\n",
    "    return out_arr\n",
    "\n",
    "\n",
    "def getdata(train=55000, test=5000):\n",
    "    trimages, trlabels, _ = read_tfrecord('train.tfrecords', num=train, )\n",
    "    teimages, telabels, _ = read_tfrecord('test.tfrecords', num=test, )\n",
    "    # trimages = trun(trimages)\n",
    "    # teimages = trun(teimages)\n",
    "\n",
    "    return trimages, trlabels, teimages, telabels\n",
    "\n",
    "\n",
    "def main(train=55000, test=5000, batch_size=100, epochs=20):\n",
    "    trimages, trlabels, tsimages, tslabels = getdata(train=train, test=test)\n",
    "    # print(trlabels)\n",
    "    model = create_model()\n",
    "#     from keras.utils import plot_model\n",
    "#     plot_model(model, to_file='./Resnet_model.png')\n",
    "    tem = model.fit(trimages, trlabels, batch_size=batch_size, epochs=epochs, )\n",
    "    paint(tem.history)\n",
    "\n",
    "    model.evaluate(tsimages, tslabels, batch_size=batch_size)\n",
    "    model.save('./resnet.h5')\n",
    "\n",
    "\n",
    "def paint(hist):\n",
    "    import matplotlib.pyplot as plt\n",
    "    %matplotlib notebook\n",
    "    # fig = plt.figure(figsize=(6, 3))\n",
    "    ti = []\n",
    "    for i in range(len(hist['loss'])):\n",
    "        ti.append(i)\n",
    "    plt.plot(ti, hist['loss'], c='red')\n",
    "    plt.plot(ti, hist['acc'], c='blue')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def test_model(num=1000.0):\n",
    "    timages, tlabels, _ = read_tfrecord('test.tfrecords', num=int(num))\n",
    "\n",
    "    model = load_model('./resnet50.h5')\n",
    "    pre = model.predict(timages)\n",
    "    tr = 0\n",
    "    for a, b in zip(tlabels, pre):\n",
    "        a = np.argmax(a)\n",
    "        b = np.argmax(b)\n",
    "        if a == b:\n",
    "            tr += 1\n",
    "    ls = tr / num\n",
    "    print(\"正確率為：{0}\".format(ls))\n",
    "\n",
    "\n",
    "def train_model():\n",
    "    from tensorflow.examples.tutorials.mnist import input_data\n",
    "    data = input_data.read_data_sets('./data/', validation_size=5000)\n",
    "    model = load_model('./resnet.h5')\n",
    "    model.fit()\n",
    "\n",
    "\n",
    "def test():\n",
    "    from tensorflow.examples.tutorials.mnist import input_data\n",
    "    data = input_data.read_data_sets('./data/', validation_size=5000)\n",
    "    data = data.train.next_batch(5000)\n",
    "    img = []\n",
    "    label = []\n",
    "    for i in data[0]:\n",
    "        i = np.reshape(i, [28, 28])\n",
    "        img.append(i)\n",
    "    print(\"轉換完成\")\n",
    "    for i in data[1]:\n",
    "        tem = np.zeros((1, 10))\n",
    "        tem[0][i] = 1.0\n",
    "        label.append(tem[0])\n",
    "    print('轉換完成')\n",
    "    model = create_model()\n",
    "    model.fit(img, label, batch_size=50, epochs=5, )\n",
    "    model.evaluate(img, label, batch_size=50)\n",
    "    model.save('./resnet_test.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()\n",
    "\n",
    "    # test()\n",
    "    # test_model(num=5000)\n",
    "    # x_train = np.random.random((2,5,5))\n",
    "    # print(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 三、實踐總結"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
