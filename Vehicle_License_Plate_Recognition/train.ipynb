{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Vehicle License Plate Recognition 之 train model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 一、構建模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import keras\n",
    "from keras.models import model_from_json, load_model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.layers import Conv2D, BatchNormalization, MaxPooling2D, Input\n",
    "from keras.layers import AveragePooling2D, Flatten, GlobalMaxPooling2D\n",
    "from keras import layers\n",
    "from keras.models import Model\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "config = {'黑': 36, 'B': 19, '桂': 45, '2': 62, '陕': 29, '浙': 48, 'N': 3, '1': 58, 'K': 20, 'T': 6, '津': 49, '闽': 44,\n",
    "          'X': 17, '粤': 47, 'Q': 16, 'V': 15, '琼': 41, '皖': 46, '沪': 32, '冀': 52, '鲁': 50, '贵': 35, '川': 31, '吉': 25,\n",
    "          '豫': 34, '6': 57, 'L': 21, '5': 63, '晋': 28, '4': 60, 'E': 18, '云': 38, 'S': 7, 'J': 12, 'G': 4, '赣': 30,\n",
    "          'A': 8, 'D': 14, '湘': 40, '鄂': 51, '0': 55, '蒙': 43, 'Y': 22, '辽': 37, 'U': 2, '3': 61, '9': 54, 'W': 24,\n",
    "          'Z': 5, 'P': 23, 'F': 9, 'M': 11, '8': 59, '7': 56, 'R': 1, 'H': 10, '青': 27, 'C': 13, '苏': 33, '甘': 42,\n",
    "          '宁': 26, '京': 53, '渝': 39}\n",
    "config_ = dict(zip(config.values(), config.keys()))\n",
    "\n",
    "\n",
    "# print(config_)\n",
    "\n",
    "def conv_block(input_tensor, bn_axis, filters, phase, name, strides=(1, 1)):\n",
    "    \"\"\"\n",
    "    Conv2D 塊，雙路雙卷積計算\n",
    "    :param input_tensor:(tensor) 輸入張量\n",
    "    :param filters:(tuple) 卷積核打包\n",
    "    :param strides:(int) 卷積步長\n",
    "    :param BN_axis:(int) 規範化卷積軸\n",
    "    :return: model\n",
    "    \"\"\"\n",
    "    filters1, filters2, filters3 = filters  # 解包卷積核數量\n",
    "    Conv_base_name = 'Conv_' + name + '_' + str(phase) + '_phase_'\n",
    "    BN_base_name = 'BN_' + name + '_' + str(phase) + '_phase_'\n",
    "    x = Conv2D(\n",
    "        filters=filters1, kernel_size=(1, 1), strides=strides, name=Conv_base_name + '2a'\n",
    "    )(input_tensor)\n",
    "    x = BatchNormalization(axis=bn_axis, name=BN_base_name + '2a')(x)\n",
    "    x = Activation(activation='relu')(x)\n",
    "\n",
    "    x = Conv2D(\n",
    "        filters=filters2, kernel_size=(1, 1), strides=strides, name=Conv_base_name + '2b'\n",
    "    )(x)\n",
    "    x = BatchNormalization(axis=bn_axis, name=BN_base_name + '2b')(x)\n",
    "    x = Activation(activation='relu')(x)\n",
    "\n",
    "    x = Conv2D(\n",
    "        filters=filters3, kernel_size=(1, 1), strides=strides, name=Conv_base_name + '2c'\n",
    "    )(x)\n",
    "    x = BatchNormalization(axis=bn_axis, name=BN_base_name + '2c')(x)\n",
    "    x = Activation(activation='relu')(x)\n",
    "\n",
    "    y = Conv2D(filters3, (1, 1), strides=strides, name=Conv_base_name + '1a')(input_tensor)\n",
    "    y = BatchNormalization(axis=bn_axis, name=BN_base_name + '1b')(y)\n",
    "\n",
    "    x = layers.add([x, y])\n",
    "    a = Activation('relu')(x)\n",
    "\n",
    "    return a\n",
    "\n",
    "\n",
    "def identity_block(input_tensor, bn_axis, filters, phase, name, strides=(1, 1)):\n",
    "    \"\"\"\n",
    "    Conv2D 塊，雙路單卷積計算\n",
    "    :param input_tensor:(tensor) 輸入張量\n",
    "    :param filters:(tuple) 卷積核打包\n",
    "    :param strides:(int) 卷積步長\n",
    "    :param BN_axis:(int) 規範化卷積軸\n",
    "    :return: model\n",
    "    \"\"\"\n",
    "    filters1, filters2, filters3 = filters  # 解包卷積核數量\n",
    "    Conv_base_name = 'Conv_' + name + '_' + str(phase) + '_phase_'\n",
    "    BN_base_name = 'BN_' + name + '_' + str(phase) + '_phase_'\n",
    "    x = Conv2D(\n",
    "        filters=filters1, kernel_size=(1, 1), strides=strides, name=Conv_base_name + '2a'\n",
    "    )(input_tensor)\n",
    "    x = BatchNormalization(axis=bn_axis, name=BN_base_name + '2a')(x)\n",
    "    x = Activation(activation='relu')(x)\n",
    "\n",
    "    x = Conv2D(\n",
    "        filters=filters2, kernel_size=(1, 1), strides=strides, name=Conv_base_name + '2b'\n",
    "    )(x)\n",
    "    x = BatchNormalization(axis=bn_axis, name=BN_base_name + '2b')(x)\n",
    "    x = Activation(activation='relu')(x)\n",
    "\n",
    "    x = Conv2D(\n",
    "        filters=filters3, kernel_size=(1, 1), strides=strides, name=Conv_base_name + '2c'\n",
    "    )(x)\n",
    "    x = BatchNormalization(axis=bn_axis, name=BN_base_name + '2c')(x)\n",
    "    x = Activation(activation='relu')(x)\n",
    "\n",
    "    x = layers.add([x, input_tensor])\n",
    "    a = Activation('relu')(x)\n",
    "\n",
    "    return a\n",
    "\n",
    "\n",
    "def my_resnet():\n",
    "    inputs = Input(shape=(1, 24, 48))\n",
    "\n",
    "    x = Conv2D(\n",
    "        filters=4, kernel_size=(2, 4), padding='same', name='Conv1', data_format='channels_first')(inputs)\n",
    "    x = BatchNormalization(axis=1, name='BN_Conv1')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    MaxPooling2D(pool_size=(2, 2), strides=(2, 2), data_format='channels_first')(x)\n",
    "\n",
    "    x = conv_block(input_tensor=x, bn_axis=1, filters=(4, 4, 64), phase=2, name='a')\n",
    "    x = identity_block(input_tensor=x, bn_axis=1, filters=(4, 4, 64), phase=2, name='b')\n",
    "    x = identity_block(input_tensor=x, bn_axis=1, filters=(4, 4, 64), phase=2, name='c')\n",
    "\n",
    "    # x = conv_block(input_tensor=x, bn_axis=1, filters=(8, 8, 512), phase=3, name='a')\n",
    "    # x = identity_block(input_tensor=x, bn_axis=1, filters=(8, 8, 512), phase=3, name='b')\n",
    "    # x = identity_block(input_tensor=x, bn_axis=1, filters=(8, 8, 512), phase=3, name='c')\n",
    "\n",
    "    x = AveragePooling2D((2, 2), name='avg_pool')(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(64, activation='softmax', name='softmax')(x)\n",
    "    #     x = GlobalMaxPooling2D()(x)\n",
    "\n",
    "    model = Model(inputs, x, name='My_Resnet')\n",
    "    return model\n",
    "\n",
    "\n",
    "def create_model():\n",
    "    \"\"\"返回一個已創建好的 resnet model\"\"\"\n",
    "    model = my_resnet()\n",
    "    model.compile(optimizer='rmsprop',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "def get_tfrecord(filename='train.tfrecords', num=1000):\n",
    "    num=int(num)\n",
    "    # 將製作好的 tfrecord 數據集文件讀取出來,並轉換成圖片,以驗證數據是否準確無誤\n",
    "    print('開始導入數據' + filename)\n",
    "    filename_queue = tf.train.string_input_producer([filename])  # 讀入數據流\n",
    "    reader = tf.TFRecordReader()\n",
    "    _, serialized_example = reader.read(filename_queue)  # 返回文件名和文件\n",
    "    features = tf.parse_single_example(serialized_example,\n",
    "                                       features={\n",
    "                                           'label': tf.FixedLenFeature([], tf.string),\n",
    "                                           'img_val': tf.FixedLenFeature([], tf.string),\n",
    "                                       })  # 取出包含image和label的feature对象\n",
    "    image = tf.decode_raw(features['img_val'], tf.uint8)\n",
    "    label = tf.cast(features['label'], tf.string)\n",
    "\n",
    "    imgdata = []\n",
    "    imglabel = []\n",
    "    with tf.Session() as sess:  # 開始一個對話\n",
    "        init_op = tf.global_variables_initializer()\n",
    "        sess.run(init_op)\n",
    "        coord = tf.train.Coordinator()\n",
    "        threads = tf.train.start_queue_runners(coord=coord)\n",
    "        tem = np.zeros((num, 64))\n",
    "        for i in range(num):\n",
    "#             if i % 1000 == 0:\n",
    "#                 print('已完成導入數據' + filename + str(i) + '個')\n",
    "            example, l = sess.run([image, label])  # 在會話中取出image和label數據\n",
    "            data = np.resize(example, [48, 24, 3])\n",
    "            data = turn_two_color(data)\n",
    "            tem[i][config[l.decode('utf-8')]] = 1\n",
    "            imgdata.append([data])\n",
    "            imglabel.append(tem[0])\n",
    "        coord.request_stop()\n",
    "        coord.join(threads)\n",
    "    print('導入數據' + filename + '完成')\n",
    "    return imgdata, tem\n",
    "\n",
    "\n",
    "def turn_two_color(data):\n",
    "    \"\"\"\n",
    "    圖片二值化\n",
    "    :param data: 圖片\n",
    "    :return: 二值化後的數據\n",
    "    \"\"\"\n",
    "    import cv2\n",
    "    grayImage = cv2.cvtColor(data, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    a = 0\n",
    "    for i in grayImage:\n",
    "        b = 0\n",
    "        for j in i:\n",
    "            if j < grayImage.mean():  # 比对均值\n",
    "                grayImage[a][b] = 0\n",
    "            else:\n",
    "                grayImage[a][b] = 255\n",
    "            b += 1\n",
    "        a += 1\n",
    "        del b\n",
    "    grayImage = np.resize(grayImage, [24, 48])\n",
    "    return grayImage\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(batch_size=100, epochs=10):\n",
    "    model = create_model()\n",
    "    tr_data, tr_label = get_tfrecord(num=13000)\n",
    "    va_data, va_label = get_tfrecord('validation.tfrecords', num=1000)\n",
    "    print('數據導入完成，開始計算')\n",
    "    tem = model.fit(tr_data, tr_label, batch_size=batch_size, epochs=epochs, )\n",
    "\n",
    "    # print(tem.history)\n",
    "    model.evaluate(va_data, va_label, batch_size=batch_size)\n",
    "    model.save('./resnet_1.h5')\n",
    "    \n",
    "\n",
    "\n",
    "# main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "開始導入數據test.tfrecords\n",
      "導入數據test.tfrecords完成\n",
      "正確率為：0.972\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.972"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def test_model(num=1000.0,filename='test.tfrecords',modelname='./resnet.h5'):\n",
    "    ts_images, ts_labels = get_tfrecord(filename,num)\n",
    "\n",
    "    model = load_model(modelname)\n",
    "    pre = model.predict(ts_images)\n",
    "    tr = 0\n",
    "    for a, b in zip(ts_labels, pre):\n",
    "        a = np.argmax(a)\n",
    "        b = np.argmax(b)\n",
    "        if a == b:\n",
    "            tr += 1\n",
    "#         else:\n",
    "#             print('真確：' + config_[a] + \" 預測：\" + config_[b])\n",
    "    ls = tr / num\n",
    "    print(\"正確率為：{0}\".format(ls))\n",
    "    del ts_images,ts_labels,model,pre\n",
    "    return ls\n",
    "\n",
    "test_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "開始導入數據train.tfrecords\n",
      "導入數據train.tfrecords完成\n",
      "開始導入數據validation.tfrecords\n",
      "導入數據validation.tfrecords完成\n",
      "數據導入完成，開始計算\n",
      "Epoch 1/1\n",
      "13000/13000 [==============================] - 36s 3ms/step - loss: 1.6935 - acc: 0.6648\n",
      "開始導入數據validation.tfrecords\n",
      "導入數據validation.tfrecords完成\n",
      "正確率為：0.729\n",
      "Epoch 1/2\n",
      "13000/13000 [==============================] - 33s 3ms/step - loss: 0.4192 - acc: 0.9100\n",
      "Epoch 2/2\n",
      "13000/13000 [==============================] - 33s 3ms/step - loss: 0.2410 - acc: 0.9476\n",
      "1000/1000 [==============================] - 3s 3ms/step\n",
      "開始導入數據validation.tfrecords\n",
      "導入數據validation.tfrecords完成\n",
      "正確率為：0.914\n",
      "Epoch 1/2\n",
      "13000/13000 [==============================] - 33s 3ms/step - loss: 0.1580 - acc: 0.9668\n",
      "Epoch 2/2\n",
      "13000/13000 [==============================] - 35s 3ms/step - loss: 0.1136 - acc: 0.9774\n",
      "1000/1000 [==============================] - 3s 3ms/step\n",
      "開始導入數據validation.tfrecords\n",
      "導入數據validation.tfrecords完成\n",
      "正確率為：0.945\n",
      "Epoch 1/2\n",
      "13000/13000 [==============================] - 33s 3ms/step - loss: 0.0850 - acc: 0.9832\n",
      "Epoch 2/2\n",
      "13000/13000 [==============================] - 32s 2ms/step - loss: 0.0665 - acc: 0.9887\n",
      "1000/1000 [==============================] - 3s 3ms/step\n",
      "開始導入數據validation.tfrecords\n",
      "導入數據validation.tfrecords完成\n",
      "正確率為：0.956\n",
      "Epoch 1/2\n",
      "13000/13000 [==============================] - 33s 3ms/step - loss: 0.0539 - acc: 0.9922\n",
      "Epoch 2/2\n",
      "13000/13000 [==============================] - 32s 2ms/step - loss: 0.0468 - acc: 0.9933\n",
      "1000/1000 [==============================] - 3s 3ms/step\n",
      "開始導入數據validation.tfrecords\n",
      "導入數據validation.tfrecords完成\n",
      "正確率為：0.957\n",
      "Epoch 1/2\n",
      "13000/13000 [==============================] - 34s 3ms/step - loss: 0.0414 - acc: 0.9948\n",
      "Epoch 2/2\n",
      "13000/13000 [==============================] - 34s 3ms/step - loss: 0.0377 - acc: 0.9960\n",
      "1000/1000 [==============================] - 3s 3ms/step\n",
      "開始導入數據validation.tfrecords\n",
      "導入數據validation.tfrecords完成\n",
      "正確率為：0.967\n",
      "開始導入數據test.tfrecords\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'float' object cannot be interpreted as an integer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-7081a5520c1c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-9-7081a5520c1c>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mtest_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'validation.tfrecords'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mtest_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-3bc903d323c4>\u001b[0m in \u001b[0;36mtest_model\u001b[0;34m(num, filename, modelname)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtest_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'test.tfrecords'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodelname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'./resnet.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mts_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mts_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_tfrecord\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodelname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mpre\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mts_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-040615e56104>\u001b[0m in \u001b[0;36mget_tfrecord\u001b[0;34m(filename, num)\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0mcoord\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCoordinator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0mthreads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_queue_runners\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoord\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcoord\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m         \u001b[0mtem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;31m#             if i % 1000 == 0:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'float' object cannot be interpreted as an integer"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Error reported to Coordinator: <class 'tensorflow.python.framework.errors_impl.CancelledError'>, Run call was cancelled\n"
     ]
    }
   ],
   "source": [
    "def train_model():\n",
    "    model = create_model()\n",
    "    tr_data, tr_label = get_tfrecord(num=13000)\n",
    "    va_data, va_label = get_tfrecord('validation.tfrecords', num=1000)\n",
    "    print('數據導入完成，開始計算')\n",
    "    tem = model.fit(tr_data, tr_label, batch_size=128, epochs=1, )\n",
    "    model.save('./resnet.h5')\n",
    "    test_model(filename='validation.tfrecords',num=1000)\n",
    "    for i in range(5):\n",
    "        model = load_model('./resnet.h5')\n",
    "        model.fit(tr_data,tr_label,batch_size=128,epochs=2)\n",
    "        model.evaluate(va_data, va_label, batch_size=128)\n",
    "        model.save('./resnet.h5')\n",
    "        test_model(filename='validation.tfrecords',num=1000)\n",
    "        \n",
    "    test_model()\n",
    "    \n",
    "\n",
    "train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
